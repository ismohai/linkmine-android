对于你说的这个质量基线，我就觉得很离谱。因为你说可以完全本地来做，做到0 Token，我就觉得不可思议。因为AI大模型它是有大量的数据，它是有上千亿的一个数据量，训练成的一个模型嘛。然后你本地的话呢，你首先你没有这么多的数据量，其次的话你肯定没有这么智能。你纯粹靠那个程序去计算那个概率可能性，它可能不准确。因为你程序你不是模型，你根本就不知道什么是对话，什么是叙述比例。你反正你就不知道这些东西什么是什么，你只知道这些是一串字符。还有你说的这个不主动追回收时间，这个东西的话呢？就是可能会造成大量的Token的消耗。因为伏笔这种东西，它毕竟不是说你每时每刻都要去回收嘛，也不是每时每刻都有伏笔。但是你每时每刻你都要去检查这个东西，所以每一次你都会把那个伏笔的列表给发过去，并且每次会去判断这个伏笔，这可能会造成大量的Token的一个消耗。我说的可能不太准确，反正意思就是可能会造成大量的Token被消耗，而Token被消耗了，可能这一章节压根就没有什么伏笔回收，压根也就不需要什么伏笔回收这种东西的，反正这种意思嘛。